{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a260669",
   "metadata": {},
   "source": [
    "# Extracte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51543d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed5ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv(list_csv):\n",
    "\n",
    "\n",
    "    api_url = \"https://www.data.gouv.fr/api/2/datasets/5b598be088ee387c0c353714/resources/?page=1&page_size=50\" # La requette est sur le /states/all et c'est la que les param sont important et pr√©ciser\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        print(\"Making API request... (this may take a few seconds)\")\n",
    "        \n",
    "\n",
    "\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        \n",
    "\n",
    "\n",
    "        if response.status_code == 200: #status_code = le statu html de la reponse et 200 c'est quand c'est bon\n",
    "            print(\"Cela fonctionne\")\n",
    "\n",
    "\n",
    "\n",
    "            data = response.json() # Vas cherche les donn√©es de la request (voir ca comme les ROS)\n",
    "        \n",
    "            for part in data.get('data', []):\n",
    "\n",
    "                title = part.get('title')\n",
    "                \n",
    "\n",
    "                if title in  list_csv:\n",
    "                    \n",
    "                    url_csv  = part.get('url')\n",
    "\n",
    "                    requests_csv = requests.get(url_csv)\n",
    "\n",
    "                    if requests_csv.status_code == 200:\n",
    "\n",
    "                        with open(\"data/\"+ title, \"wb\") as f:\n",
    "                            f.write(requests_csv.content)\n",
    "\n",
    "\n",
    "        print(f\"Created all CSV\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Network error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d000d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(list_chemin):\n",
    "\n",
    "    # print(\"üìÑ Reading tourism data from CSV...\")\n",
    "    \n",
    "    try:\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chemin in list_chemin:\n",
    "            df = pd.concat([df, pd.read_csv(\"../data/\"+ chemin)], ignore_index=True)\n",
    "\n",
    "        print('Data retreived in a dataframe')\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151915d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = [\"datatourisme-reg-ara.csv\", \"datatourisme-reg-bfc.csv\", \"datatourisme-reg-bre.csv\",\n",
    "        \"datatourisme-reg-cor.csv\", \"datatourisme-reg-cvl.csv\", \"datatourisme-reg-gde.csv\",\n",
    "        \"datatourisme-reg-hdf.csv\", \"datatourisme-reg-naq.csv\", \"datatourisme-reg-nor.csv\",\n",
    "        \"datatourisme-reg-idf.csv\",  \"datatourisme-reg-occ.csv\", \"datatourisme-reg-pac.csv\",\n",
    "        \"datatourisme-reg-pdl.csv\"] # \"datatourisme-reg-guf\", \"datatourisme-reg-myt\", , \"datatourisme-reg-reu\", \"datatourisme-reg-glp\",\"datatourisme-reg-mtq\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa748f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API request... (this may take a few seconds)\n",
      "Cela fonctionne\n",
      "‚ùå Error processing data: [Errno 2] No such file or directory: 'data/datatourisme-reg-pdl.csv'\n",
      "‚ùå Error reading data: [Errno 2] No such file or directory: '../data/datatourisme-reg-ara.csv'\n"
     ]
    }
   ],
   "source": [
    "extract_csv(list_df)\n",
    "\n",
    "df = extract_data(list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04eeab",
   "metadata": {},
   "source": [
    "# Transforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cluster ###\n",
    "\n",
    "\n",
    "\n",
    "# A garder score cacher qui compte sans un poids du client\n",
    "Logement = ['Hotel', 'BedAndBreakfast', 'HotelRestaurant', 'Hostel', 'CampingAndCaravanning',\n",
    "            'Accommodation', 'HotelTrade', 'RentalAccommodation', 'CollectiveAccommodation', 'TableHoteGuesthouse',\n",
    "            \"AccommodationProduct\", 'Guesthouse', 'House'] # LodgingBusiness = logement qui accepte les buisness\n",
    "\n",
    "# A garder score cacher qui compte sans un poids du client\n",
    "tourism_center = [\"TouristInformationCenter\"]\n",
    "\n",
    "# Garder\n",
    "Nourriture = [\"FoodEstablishment\", 'Restaurant', 'CafeOrCoffeeShop', 'IceCreamShop', 'Bakery']\n",
    "\n",
    "# Garder\n",
    "Event = ['SaleEvent', 'TheaterEvent', 'Event', 'Festival', 'MusicEvent', \"SportsEvent\", 'TraditionalCelebration', 'ShowEvent', 'ChildrensEvent',\n",
    "         'Concert', 'Exhibition', 'LocalAnimation', 'Rambling']\n",
    "\n",
    "# A garder score cacher qui compte sans un poids du client\n",
    "transport = ['Transport', 'TrainStation', 'BusStation', 'Transporter', 'Airport', 'TaxiCompany'] # Transport = principalement des ports/ BusStation = gare routi√®re\n",
    "\n",
    "# Garder\n",
    "activit√©s = ['Product', 'Hammam', 'AmusementPark', 'Landform', 'Casino',  'BowlingAlley', 'RailBike', 'MiniGolf', 'AdventurePark'\n",
    "             'BalneotherapyCentre', 'SummerToboggan', 'NauticalCentre',\n",
    "             'TastingProvider', 'ActivityProvider',  'Rental', 'Trampoline', 'EquestrianCenter', 'EquipmentRental',\n",
    "             \"Tour\", 'LeisureSportActivityProvider', 'Practice', 'EntertainmentAndEvent', 'MegalithDolmenMenhir', 'TrainingWorkshop', 'TeachingFarm',\n",
    "             \"CulturalActivityProvider\", 'Cinematheque', 'Visit', 'WalkingTour'] # Product = visite en tt genre / Landform = Plage /  Tour = sentier de rando\n",
    "\n",
    "# A garder\n",
    "Sport = ['SportsAndLeisurePlace', 'OrderedList',  'GolfCourse', 'ClimbingWall', 'TennisComplex', \n",
    "         \"CyclingTour\", 'TerrainPark', 'FrontonBelotaCourt', 'SportsClub'] # OrderedList = rando + VTT\n",
    "\n",
    "# A garder\n",
    "Sport_hiver = ['CrossCountrySkiTrail', 'DownhillSkiRun', 'DownhillSkiResort', 'CrossCountrySkiResort']\n",
    "\n",
    "\n",
    "# A garder\n",
    "Balade = ['NaturalHeritage', 'ServiceArea','EducationalTrail', 'ViaFerrata', 'RomanPath', 'LevyOrDike',] # ServiceArea = Site pour observer les √©toile / EducationalTrail = balade / LevyOrDike = balade de barrage\n",
    "\n",
    "# A garder\n",
    "Park = ['Park', 'CivicStructure', 'PicnicArea', 'ParkAndGarden'] # CivicStructure = Parcoure de sant√©, air de jeux\n",
    "\n",
    "Magasin = ['CoveredMarket', \"Store\", 'Market', 'LocalProductsShop', 'BoutiqueOrLocalShop']\n",
    "\n",
    "\n",
    "# A garder\n",
    "Culture = ['Church', 'RemarkableBuilding', 'TechnicalHeritage', 'Cloister', 'Cathedral', 'FortifiedCastle', 'Palace', \n",
    "            'Fort', 'ReligiousSite', 'Temple', \"Ruins\", \"RemembranceSite\", 'Dungeon', 'DefenceSite', 'Abbey', 'Convent', \n",
    "            'Monastery', 'Collegiate', 'Tower', 'Fountain','Chapel', 'Mine', 'Bridge', 'Basilica', 'Chartreuse',\n",
    "            'BuddhistTemple', 'Mosque', 'Aqueduct', 'ArcheologicalSite',\"Castle\", 'Synagogue', 'FortifiedSet', 'Citadel', \n",
    "            \"RemarkableHouse\", \"Commanderie\", 'Marina', 'Bastide', 'Lighthouse','Arena', 'LocalBusiness', 'Aquarium', \n",
    "            \"CulturalSite\", 'Theater', \"Library\", 'Museum'] # RemembranceSite = Memoriale,...\n",
    "\n",
    "# A garder\n",
    "Sortie_soir = ['Winery', 'NightClub', 'BistroOrWineBar', 'BrasserieOrTavern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "Liste_to_keep = ['Winery', 'NightClub', 'BistroOrWineBar', 'BrasserieOrTavern', 'Church', 'RemarkableBuilding', 'TechnicalHeritage', \n",
    "           'Cloister', 'Cathedral', 'FortifiedCastle', 'Palace', 'BalneotherapyCentre', 'SummerToboggan', 'NauticalCentre',\n",
    "            'Fort', 'ReligiousSite', 'Temple', \"Ruins\", \"RemembranceSite\", 'Dungeon', 'DefenceSite', 'Abbey', 'Convent', \n",
    "            'Monastery', 'Collegiate', 'Tower', 'Fountain','Chapel', 'Mine', 'Bridge', 'Basilica', 'Chartreuse',\n",
    "            'BuddhistTemple', 'Mosque', 'Aqueduct', 'ArcheologicalSite',\"Castle\", 'Synagogue', 'FortifiedSet', 'Citadel', \n",
    "            \"RemarkableHouse\", \"Commanderie\", 'Marina', 'Bastide', 'Lighthouse','Arena', 'LocalBusiness', 'Aquarium', \n",
    "            \"CulturalSite\", 'Theater', \"Library\", 'Museum', 'Hotel', 'BedAndBreakfast', 'HotelRestaurant', 'Hostel', 'CampingAndCaravanning',\n",
    "            'Accommodation', 'HotelTrade', 'RentalAccommodation', 'CollectiveAccommodation', 'TableHoteGuesthouse',\n",
    "            \"AccommodationProduct\", 'Guesthouse', 'House', \"TouristInformationCenter\", \"FoodEstablishment\", 'Restaurant', 'CafeOrCoffeeShop', 'IceCreamShop', 'Bakery',\n",
    "            'SaleEvent', 'TheaterEvent', 'Event', 'Festival', 'MusicEvent', \"SportsEvent\", 'TraditionalCelebration', 'ShowEvent', 'ChildrensEvent',\n",
    "            'Concert', 'Exhibition', 'LocalAnimation', 'Rambling', 'Transport', 'TrainStation', 'BusStation', 'Transporter', 'Airport', 'TaxiCompany',\n",
    "            'Product', 'Hammam', 'AmusementPark', 'Landform', 'Casino',  'BowlingAlley', 'RailBike', 'MiniGolf', 'AdventurePark'\n",
    "            'TastingProvider', 'ActivityProvider',  'Rental', 'Trampoline', 'EquestrianCenter', 'EquipmentRental',\n",
    "            \"Tour\", 'LeisureSportActivityProvider', 'Practice', 'EntertainmentAndEvent', 'MegalithDolmenMenhir', 'TrainingWorkshop', 'TeachingFarm',\n",
    "            \"CulturalActivityProvider\", 'Cinematheque', 'Visit', 'WalkingTour', 'SportsAndLeisurePlace', 'OrderedList',  'GolfCourse', 'ClimbingWall', 'TennisComplex', \n",
    "            \"CyclingTour\", 'TerrainPark', 'FrontonBelotaCourt', 'SportsClub', 'CrossCountrySkiTrail', 'DownhillSkiRun', 'DownhillSkiResort', 'CrossCountrySkiResort',\n",
    "            'NaturalHeritage', 'ServiceArea','EducationalTrail', 'ViaFerrata', 'RomanPath', 'LevyOrDike','Park', 'CivicStructure', 'PicnicArea', 'ParkAndGarden',\n",
    "            'CoveredMarket', \"Store\", 'Market', 'LocalProductsShop', 'BoutiqueOrLocalShop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorie_dict = {\n",
    "    \"Logement\": Logement,\n",
    "    \"Tourism_center\": tourism_center,\n",
    "    \"Nourriture\": Nourriture,\n",
    "    \"Event\": Event,\n",
    "    \"Transport\": transport,\n",
    "    \"Activit√©s\": activit√©s,\n",
    "    \"Sport\": Sport,\n",
    "    \"Sport_hiver\": Sport_hiver,\n",
    "    \"Balade\": Balade,\n",
    "    \"Park\": Park,\n",
    "    \"Magasin\": Magasin,\n",
    "    \"Culture\": Culture,\n",
    "    \"Sortie_soir\": Sortie_soir,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  \n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23dde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nearest_cluster(df, cluster_points):\n",
    "\n",
    "    poi_coords = df[[\"Latitude\", \"Longitude\"]].to_numpy()\n",
    "    clusters = np.array(cluster_points)\n",
    "\n",
    "\n",
    "\n",
    "    distances = np.array([distance(poi_coords[:, 0], poi_coords[:, 1], lat_c, lon_c) for (lat_c, lon_c) in clusters]).T  \n",
    "\n",
    "    df[\"id_cluster\"] = np.argmin(distances, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assigne_cluster(df, df_cluster):\n",
    "    poi_code_postale = np.array(df['Code_postale'].values)\n",
    "\n",
    "    cluster_code_postale = df_cluster[['code_postal', \"zone_emploi\"]].to_numpy()\n",
    "\n",
    "    list_cluster = []\n",
    "    for poi_code in poi_code_postale:\n",
    "        for cluster_code in cluster_code_postale:\n",
    "            if poi_code == int(cluster_code[0]):\n",
    "                list_cluster.append(cluster_code[1])\n",
    "\n",
    "    dict_to_add = {\"Cluster_id\" : list_cluster}\n",
    "    df_temp = pd.DataFrame(dict_to_add)\n",
    "\n",
    "    df.insert(2, \"Cluster_id\", df_temp[\"Cluster_id\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_tourism, A_garder, categorie_dict, df_cluster):\n",
    "\n",
    "    if df_tourism.empty:\n",
    "        print(\"‚ö†Ô∏è  No airport data to clean\")\n",
    "        return df_tourism\n",
    "    \n",
    "    print(f\"üßπ Cleaning  data...\")\n",
    "    print(f\"Starting with {len(df_tourism)} \")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df_tourism.copy()\n",
    "\n",
    "    # Drop the usless data\n",
    "    df.drop(['Periodes_regroupees', 'Covid19_mesures_specifiques', 'Contacts_du_POI', 'Classements_du_POI', 'SIT_diffuseur'], axis=1)\n",
    "\n",
    "\n",
    "    # On r√©cup√®re uniquement les cat√©gorie de POI\n",
    "    df[\"Categories_de_POI\"] = df[\"Categories_de_POI\"].str.split('/').str[-1]\n",
    "    df[\"Categories_de_POI\"] = df[\"Categories_de_POI\"].str.split('#').str[-1]\n",
    "\n",
    "    # On d√©coupe la colone en 3 pour plus de clareter\n",
    "    col_index = df.columns.get_loc(\"Code_postal_et_commune\")\n",
    "\n",
    "    df_temp = df[\"Code_postal_et_commune\"].str.split('#', expand=True)\n",
    "    df_temp.columns = [\"Code_postale\", \"Commune\"]\n",
    "    df_temp[\"D√©partement\"] = df_temp[\"Code_postale\"].str[0:2].astype(int)\n",
    "\n",
    "    df.drop(columns=[\"Code_postal_et_commune\"], inplace=True)\n",
    "\n",
    "\n",
    "    df.insert(col_index, \"D√©partement\", df_temp[\"D√©partement\"])\n",
    "    df.insert(col_index + 1, \"Code_postale\", df_temp[\"Code_postale\"])\n",
    "    df.insert(col_index + 2, \"Commune\", df_temp[\"Commune\"])\n",
    "\n",
    "    # On drop les valeur null\n",
    "    df = df.dropna(subset=[\"Nom_du_POI\", \"Categories_de_POI\", 'Latitude', 'Longitude']) # ,\"Adresse_postale\"]) \n",
    "\n",
    "    # Passage des dates en format date\n",
    "    df[\"Date_de_mise_a_jour\"] = pd.to_datetime(df[\"Date_de_mise_a_jour\"])\n",
    "\n",
    "    \n",
    "\n",
    "    # --- √âtape 1 : filtrer selon A_garder ---\n",
    "    df = df[df[\"Categories_de_POI\"].isin(A_garder)].copy()\n",
    "\n",
    "    # --- √âtape 2 : ajouter la cat√©gorie simplifi√©e ---\n",
    "    def find_category(cat):\n",
    "        for key, values in categorie_dict.items():\n",
    "            if cat in values:\n",
    "                return key\n",
    "        return \"Autre\"  # si aucune correspondance trouv√©e\n",
    "\n",
    "    df.insert(3, 'Categorie_simplifiee', df[\"Categories_de_POI\"].apply(find_category)) \n",
    "\n",
    "\n",
    "    df[\"nb_nan\"] = df.isna().sum(axis=1)\n",
    "\n",
    "    # Trier pour que la ligne avec le moins de NaN soit en premier dans chaque groupe\n",
    "    df = df.sort_values(by=[\"Nom_du_POI\", \"nb_nan\"], ascending=[True, True])\n",
    "\n",
    "    # Supprimer les doublons, en gardant la premi√®re (celle avec le moins de NaN)\n",
    "    df = df.drop_duplicates(subset=\"Nom_du_POI\", keep=\"first\")\n",
    "\n",
    "    # Supprimer la colonne temporaire\n",
    "    df = df.drop(columns=\"nb_nan\")\n",
    "\n",
    "    # (optionnel) R√©indexer proprement\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df.insert(0, 'ID', df[\"URI_ID_du_POI\"].str.split('/').str[-1])\n",
    "\n",
    "    df = df.sort_values(by=['D√©partement'], ascending=[True]).reset_index(drop=True)\n",
    "    \n",
    "    df['Code_postale'] = df['Code_postale'].astype(float)\n",
    "\n",
    "    df_cluster = df_cluster.rename(columns={'code_postal': 'Code_postale'})\n",
    "\n",
    "    # Fusion (jointure) sur le code postal\n",
    "    df_merged = df.merge(\n",
    "        df_cluster[['Code_postale', 'zone_emploi']], \n",
    "        on='Code_postale', \n",
    "        how='left'  # garde tous les POI m√™me sans cluster\n",
    "    )\n",
    "\n",
    "    # Renommer la colonne r√©sultante pour plus de clart√©\n",
    "    df_merged = df_merged.rename(columns={'zone_emploi': 'Cluster_id'})\n",
    "\n",
    "    print(f'Il reste {len(df)} data apr√®s nettoyage.') \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297d5cf",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b1a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_CONFIG = {\n",
    "    'username': 'alexm',\n",
    "    'password': '', \n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'airlife_db'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44882a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection_string():\n",
    "    \"\"\"Build PostgreSQL connection string\"\"\"\n",
    "    return f\"postgresql://{DATABASE_CONFIG['username']}:{DATABASE_CONFIG['password']}@{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01229da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_database(Tourisme_df):\n",
    "\n",
    "    print(\"üíæ Loading data to PostgreSQL database...\")\n",
    "\n",
    "    connection_string = get_connection_string()\n",
    "\n",
    "    try:\n",
    "\n",
    "        engine = create_engine(connection_string)\n",
    "\n",
    "        Tourisme_df.to_sql(\"airports\", con = engine, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(Tourisme_df)} airports to database\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data to database: {e}\")\n",
    "        print(\"üí° Make sure:\")\n",
    "        print(\"   - PostgreSQL is running\")\n",
    "        print(\"   - Database 'airlife_db' exists\") \n",
    "        print(\"   - Username and password are correct\")\n",
    "        print(\"   - Tables are created (run database_setup.sql)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
